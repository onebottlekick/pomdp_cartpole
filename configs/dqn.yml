# Training configuration
train:
  seeds: [12, 34, 56, 78, 90]
  batch_size: 64
  learning_rate: 5e-4
  optimizer: adam
  n_warmup_batches: 5
  update_target_every_steps: 10
  random_sample: True

# Network configuration
network:
  model: dqn
  net_type: linear
  in_dim: 128
  num_layers: 2

# Environment configuration
env:
  version: v1
  mdp: FOMDP
  render: False

# Agent configuration
agent:
  gamma: 1.0
  max_minutes: 20
  max_episodes: 10000
  goal_mean_100_reward: 475

# Strategy configuration
strategy:
  init_epsilon: 1.0
  min_epsilon: 0.3
  decay_steps: 20000