# Training configuration
train:
  seeds: [12, 34, 56, 78, 90]
  seq_len: 128
  learning_rate: 5e-4
  optimizer: rmsprop
  max_gradient_norm: inf
  n_warmup_batches: 5
  update_target_every_steps: 10
  tau: 0.1
  random_sample: True

# Network configuration
network:
  model: mtqn
  net_type: mtq
  in_dim: 64
  num_layers: 2
  num_heads: 8
  memory_len: 64

# Environment configuration
env:
  version: v1
  mdp: POMDP
  render: False

# Agent configuration
agent:
  gamma: 0.99
  max_minutes: 10000
  max_episodes: 10000
  goal_mean_100_reward: 475

# Strategy configuration
strategy:
  init_epsilon: 1.0
  min_epsilon: 0.3
  decay_steps: 20000