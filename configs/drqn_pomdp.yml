# Training configuration
train:
  seeds: [12, 34, 56, 78, 90]
  seq_len: 64
  learning_rate: 5e-4
  optimizer: rmsprop
  n_warmup_batches: 5
  update_target_every_steps: 10
  random_sample: True

# Network configuration
network:
  model: drqn
  net_type: lstm
  in_dim: 128
  num_layers: 1

# Environment configuration
env:
  version: v1
  mdp: POMDP
  render: False

# Agent configuration
agent:
  gamma: 1.0
  max_minutes: 180
  max_episodes: 10000
  goal_mean_100_reward: 475

# Strategy configuration
strategy:
  init_epsilon: 1.0
  min_epsilon: 0.3
  decay_steps: 20000